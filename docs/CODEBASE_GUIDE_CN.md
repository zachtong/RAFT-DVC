# RAFT-DVC ä»£ç åº“å®Œæ•´æŒ‡å—

> æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å½“å‰å®ç°çš„RAFT-DVCä»£ç åº“ç»“æ„ã€æ¨¡å‹æ¶æ„ã€è®­ç»ƒå’Œæ¨ç†æµç¨‹
> åŸºäº volRAFT (CVPR 2024) çš„3Då…‰æµç½‘ç»œå®ç°

---

## ğŸ“ ç›®å½•ç»“æ„

```
RAFT-DVC/
â”‚
â”œâ”€â”€ src/                                # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ core/                          # æ ¸å¿ƒç½‘ç»œæ¶æ„ (å·²å®Œæˆ)
â”‚   â”‚   â”œâ”€â”€ raft_dvc.py                # ä¸»æ¨¡å‹ç±»
â”‚   â”‚   â”œâ”€â”€ extractor.py               # ç‰¹å¾æå–å™¨
â”‚   â”‚   â”œâ”€â”€ corr.py                    # ç›¸å…³æ€§è®¡ç®—
â”‚   â”‚   â”œâ”€â”€ update.py                  # GRUæ›´æ–°æ¨¡å—
â”‚   â”‚   â””â”€â”€ utils.py                   # å·¥å…·å‡½æ•°
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                          # æ•°æ®åŠ è½½å’Œç”Ÿæˆ (å·²å®Œæˆ)
â”‚   â”‚   â”œâ”€â”€ dataset.py                 # PyTorch Datasetç±»
â”‚   â”‚   â””â”€â”€ synthetic.py               # åˆæˆæ•°æ®ç”Ÿæˆå™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                      # è®­ç»ƒç›¸å…³ (å·²å®Œæˆ)
â”‚   â”‚   â”œâ”€â”€ trainer.py                 # è®­ç»ƒç®¡ç†å™¨
â”‚   â”‚   â””â”€â”€ loss.py                    # æŸå¤±å‡½æ•°
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/                     # æ¨ç†æ¨¡å— (æ¥å£å·²å®šä¹‰ï¼Œå¾…å®ç°)
â”‚   â”‚   â”œâ”€â”€ analyzer.py                # ä½“æ•°æ®åˆ†æå™¨
â”‚   â”‚   â”œâ”€â”€ preprocessor.py            # é¢„å¤„ç†å™¨
â”‚   â”‚   â”œâ”€â”€ tiling.py                  # åˆ†å—å’Œæ‹¼æ¥
â”‚   â”‚   â”œâ”€â”€ model_registry.py          # æ¨¡å‹æ³¨å†Œè¡¨
â”‚   â”‚   â”œâ”€â”€ pipeline.py                # æ¨ç†æµæ°´çº¿
â”‚   â”‚   â””â”€â”€ postprocessor.py           # åå¤„ç†å™¨
â”‚   â”‚
â”‚   â””â”€â”€ utils/                         # é€šç”¨å·¥å…· (æ¥å£å·²å®šä¹‰ï¼Œå¾…å®ç°)
â”‚       â”œâ”€â”€ io.py                      # æ–‡ä»¶IO
â”‚       â””â”€â”€ memory.py                  # å†…å­˜ä¼°ç®—
â”‚
â”œâ”€â”€ scripts/                           # å¯æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ train.py                       # è®­ç»ƒå…¥å£
â”‚   â””â”€â”€ infer.py                       # æ¨ç†å…¥å£
â”‚
â”œâ”€â”€ configs/                           # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ default.yaml               # é»˜è®¤è®­ç»ƒé…ç½®
â”‚   â”œâ”€â”€ models/                        # æ¨¡å‹é…ç½® (æ¨¡æ¿)
â”‚   â”‚   â”œâ”€â”€ coarse_p4_r4.yaml         # ç²—é˜¶æ®µæ¨¡å‹
â”‚   â”‚   â””â”€â”€ fine_p2_r4.yaml           # ç²¾ç»†é˜¶æ®µæ¨¡å‹
â”‚   â””â”€â”€ inference/                     # æ¨ç†ç­–ç•¥ (æ¨¡æ¿)
â”‚       â”œâ”€â”€ fast.yaml
â”‚       â”œâ”€â”€ balanced.yaml
â”‚       â””â”€â”€ accurate.yaml
â”‚
â”œâ”€â”€ checkpoints/                       # æ¨¡å‹æƒé‡
â”œâ”€â”€ data/                             # æ•°æ®é›†
â””â”€â”€ ARCHITECTURE.md                   # æ¶æ„è®¾è®¡æ–‡æ¡£
```

---

## ğŸ” æ ¸å¿ƒæ¦‚å¿µï¼šRAFT-DVC æ¶æ„

### æ•´ä½“æµç¨‹å›¾

```
è¾“å…¥: vol0 (å‚è€ƒä½“), vol1 (å½¢å˜ä½“)
  â”‚
  â”œâ”€â”€> [ç‰¹å¾æå–å™¨ BasicEncoder]
  â”‚    è¾“å‡º: fmap0, fmap1 (1/8åˆ†è¾¨ç‡, 128é€šé“)
  â”‚
  â”œâ”€â”€> [ä¸Šä¸‹æ–‡ç¼–ç å™¨ ContextEncoder]
  â”‚    è¾“å‡º: net (GRUéšè—çŠ¶æ€), context (ä¸Šä¸‹æ–‡ç‰¹å¾)
  â”‚
  â”œâ”€â”€> [ç›¸å…³æ€§é‡‘å­—å¡” CorrBlock]
  â”‚    å…¨å¯¹ç›¸å…³æ€§: fmap0 âŠ— fmap1 â†’ 6Dä½“
  â”‚    æ„å»º4å±‚é‡‘å­—å¡” (æ¯å±‚å¯¹å3ç»´åš2å€ä¸‹é‡‡æ ·)
  â”‚
  â””â”€â”€> [è¿­ä»£æ›´æ–° Ã— 12æ¬¡]
       â”‚
       â”œâ”€> [æŸ¥æ‰¾ç›¸å…³æ€§] CorrBlock.lookup(coords, radius=4)
       â”‚   ä»é‡‘å­—å¡”å„å±‚æå–9Ã—9Ã—9é‚»åŸŸ â†’ corrç‰¹å¾
       â”‚
       â”œâ”€> [è¿åŠ¨ç¼–ç ] MotionEncoder(flow, corr)
       â”‚   å°†å½“å‰flowå’Œç›¸å…³æ€§ç¼–ç æˆè¿åŠ¨ç‰¹å¾
       â”‚
       â”œâ”€> [GRUæ›´æ–°] ConvGRU3D(net, [context, motion])
       â”‚   æ›´æ–°éšè—çŠ¶æ€: net_new
       â”‚
       â”œâ”€> [é¢„æµ‹delta] FlowHead(net_new)
       â”‚   é¢„æµ‹ä½ç§»å¢é‡: delta_flow
       â”‚
       â””â”€> [æ›´æ–°åæ ‡] coords += delta_flow
           ä¸Šé‡‡æ ·åˆ°åŸåˆ†è¾¨ç‡ â†’ å½“å‰è¿­ä»£çš„flowé¢„æµ‹

è¾“å‡º: [flow_iter1, flow_iter2, ..., flow_iter12]
```

---

## ğŸ“¦ æ¨¡å—è¯¦è§£

## 1. æ ¸å¿ƒæ¶æ„ (`src/core/`)

### 1.1 `raft_dvc.py` - ä¸»æ¨¡å‹ç±»

**å…³é”®ç±»: `RAFTDVC`**

è¿™æ˜¯æ•´ä¸ªæ¨¡å‹çš„é¡¶å±‚å®¹å™¨ï¼Œåè°ƒæ‰€æœ‰å­æ¨¡å—ã€‚

```python
class RAFTDVC(nn.Module):
    """
    ä¸»è¦ç»„æˆéƒ¨åˆ†:
    1. fnet (BasicEncoder) - ç‰¹å¾æå–å™¨ï¼Œå…±äº«å¤„ç†ä¸¤ä¸ªä½“
    2. cnet (ContextEncoder) - ä¸Šä¸‹æ–‡ç¼–ç å™¨ï¼Œåªå¤„ç†å‚è€ƒä½“
    3. update_block (BasicUpdateBlock) - GRUæ›´æ–°æ¨¡å—
    """

    def forward(vol0, vol1, iters=12, flow_init=None):
        """
        å‰å‘ä¼ æ’­æµç¨‹:

        æ­¥éª¤1: å½’ä¸€åŒ–
        --------------
        - å°†vol0å’Œvol1å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
        - ä½¿ç”¨å…±äº«çš„min/maxç¡®ä¿ä¸€è‡´æ€§

        æ­¥éª¤2: ç‰¹å¾æå–
        --------------
        fmap0, fmap1 = self.fnet([vol0, vol1])
        - è¾“å…¥: (B, 1, H, W, D) åŸå§‹ç°åº¦ä½“
        - è¾“å‡º: (B, 128, H/8, W/8, D/8) ç‰¹å¾å›¾
        - é€šè¿‡stride=2çš„å·ç§¯å®ç°1/8ä¸‹é‡‡æ ·

        æ­¥éª¤3: æ„å»ºç›¸å…³æ€§é‡‘å­—å¡”
        ----------------------
        corr_fn = CorrBlock(fmap0, fmap1, num_levels=4, radius=4)
        - è®¡ç®—å…¨å¯¹ç›¸å…³æ€§: corr[b,h,w,d,:,:,:] = fmap0[b,:,h,w,d] Â· fmap1[b,:,:,:,:]
        - æ„å»º4å±‚é‡‘å­—å¡”ï¼Œæ¯å±‚å¯¹ç©ºé—´ç»´åº¦(å3ç»´)åšavg_pool

        æ­¥éª¤4: ä¸Šä¸‹æ–‡æå–
        ----------------
        net, context = self.cnet(vol0)
        - net: (B, 96, H/8, W/8, D/8) GRUåˆå§‹éšè—çŠ¶æ€
        - context: (B, 64, H/8, W/8, D/8) é™æ€ä¸Šä¸‹æ–‡ç‰¹å¾

        æ­¥éª¤5: åˆå§‹åŒ–flowåæ ‡
        --------------------
        coords0 = åŸºç¡€åæ ‡ç½‘æ ¼ (æœªåŠ¨)
        coords1 = coords0 + flow_init  (å¦‚æœæä¾›äº†åˆå§‹flow)

        æ­¥éª¤6: è¿­ä»£æ›´æ–° (å¾ªç¯12æ¬¡)
        -------------------------
        for iter in range(iters):
            coords1 = coords1.detach()  # é˜»æ–­æ¢¯åº¦

            # 6.1 æŸ¥æ‰¾ç›¸å…³æ€§
            corr = corr_fn(coords1)  # åœ¨å½“å‰åæ ‡å¤„é‡‡æ ·9Ã—9Ã—9é‚»åŸŸ

            # 6.2 è®¡ç®—å½“å‰flow
            flow = coords1 - coords0

            # 6.3 GRUæ›´æ–°
            net, delta_flow = self.update_block(net, context, corr, flow)

            # 6.4 æ›´æ–°åæ ‡
            coords1 = coords1 + delta_flow

            # 6.5 ä¸Šé‡‡æ ·åˆ°åŸåˆ†è¾¨ç‡
            flow_up = upflow_3d(coords1 - coords0, target_shape=(H, W, D))
            flow_predictions.append(flow_up)

        è¿”å›: [flow_1, flow_2, ..., flow_12]
        æ¯ä¸ªflowçš„å½¢çŠ¶: (B, 3, H, W, D)
        """
```

**é…ç½®ç±»: `RAFTDVCConfig`**

```python
@dataclass
class RAFTDVCConfig:
    # æ¶æ„å‚æ•°
    input_channels: int = 1        # è¾“å…¥é€šé“æ•° (ç°åº¦=1)
    feature_dim: int = 128         # ç‰¹å¾æå–å™¨è¾“å‡ºç»´åº¦
    hidden_dim: int = 96           # GRUéšè—ç»´åº¦
    context_dim: int = 64          # ä¸Šä¸‹æ–‡ç»´åº¦

    # ç›¸å…³æ€§å‚æ•° (å…³é”®ï¼)
    corr_levels: int = 4           # é‡‘å­—å¡”å±‚æ•° (4å±‚: 1, 1/2, 1/4, 1/8)
    corr_radius: int = 4           # æŸ¥æ‰¾åŠå¾„ (9Ã—9Ã—9çª—å£)

    # è¿­ä»£å‚æ•°
    iters: int = 12                # é»˜è®¤è¿­ä»£æ¬¡æ•°

    # è®­ç»ƒå‚æ•°
    mixed_precision: bool = False  # æ··åˆç²¾åº¦è®­ç»ƒ
```

---

### 1.2 `extractor.py` - ç‰¹å¾æå–å™¨

**æ ¸å¿ƒç±»: `BasicEncoder`**

```python
class BasicEncoder(nn.Module):
    """
    3Dç‰¹å¾æå–å™¨ï¼ŒåŸºäºResNeté£æ ¼çš„bottleneck blocks

    æ¶æ„ç»†èŠ‚:
    ========

    è¾“å…¥: (B, 1, H, W, D)

    Layer 1: conv1 + norm + relu
    - Conv3d(1 â†’ 32, kernel=7, stride=2, padding=3)
    - è¾“å‡º: (B, 32, H/2, W/2, D/2)

    Layer 2: 2ä¸ªBottleneckBlock3D
    - BottleneckBlock3D(32 â†’ 32, stride=1)
    - BottleneckBlock3D(32 â†’ 32, stride=1)
    - è¾“å‡º: (B, 32, H/2, W/2, D/2)  # åˆ†è¾¨ç‡ä¸å˜

    Layer 3: 2ä¸ªBottleneckBlock3D
    - BottleneckBlock3D(32 â†’ 64, stride=2)  # é¦–ä¸ªblockä¸‹é‡‡æ ·
    - BottleneckBlock3D(64 â†’ 64, stride=1)
    - è¾“å‡º: (B, 64, H/4, W/4, D/4)

    Layer 4: 2ä¸ªBottleneckBlock3D
    - BottleneckBlock3D(64 â†’ 96, stride=2)  # é¦–ä¸ªblockä¸‹é‡‡æ ·
    - BottleneckBlock3D(96 â†’ 96, stride=1)
    - è¾“å‡º: (B, 96, H/8, W/8, D/8)

    Output projection:
    - Conv3d(96 â†’ 128, kernel=1)
    - è¾“å‡º: (B, 128, H/8, W/8, D/8)

    å…³é”®ç‚¹:
    ------
    1. æ€»ä¸‹é‡‡æ ·ç‡ = 1/8 (é€šè¿‡3æ¬¡stride=2å®ç°)
    2. ä½¿ç”¨InstanceNorm (é»˜è®¤) æˆ– BatchNorm / GroupNorm
    3. BottleneckBlockç»“æ„: 1Ã—1 conv â†’ 3Ã—3 conv â†’ 1Ã—1 conv + residual
    4. æ”¯æŒbatch processing: å¯ä»¥åŒæ—¶å¤„ç†[vol0, vol1]
    """

    def forward(self, x):
        """
        x å¯ä»¥æ˜¯:
        - å•ä¸ªtensor: (B, C, H, W, D)
        - åˆ—è¡¨/å…ƒç»„: [vol0, vol1]ï¼Œä¼šå…ˆconcatå†split

        å¤„ç†é€»è¾‘:
        if isinstance(x, (list, tuple)):
            x = torch.cat(x, dim=0)  # æ‹¼æ¥æˆ2B batch
            ...å¤„ç†...
            x = torch.split(x, [B, B], dim=0)  # åˆ†å›ä¸¤ä¸ª
            return (fmap0, fmap1)
        else:
            ...å¤„ç†...
            return fmap
        """
```

**è¾…åŠ©ç±»: `BottleneckBlock3D`**

```python
class BottleneckBlock3D(nn.Module):
    """
    3D Bottleneckæ®‹å·®å—

    ç»“æ„:
    ----
    è¾“å…¥x: (B, in_planes, H, W, D)

    ä¸»è·¯å¾„:
    1. Conv3d(in â†’ mid, 1Ã—1Ã—1) + norm + relu
       mid = planes // 4  (é€šé“å‹ç¼©)
    2. Conv3d(mid â†’ mid, 3Ã—3Ã—3, stride) + norm + relu
       å¦‚æœstride=2ï¼Œç©ºé—´ç»´åº¦å‡åŠ
    3. Conv3d(mid â†’ planes, 1Ã—1Ã—1) + norm
       æ¢å¤é€šé“æ•°

    æ®‹å·®è·¯å¾„ (å¦‚æœç»´åº¦ä¸åŒ¹é…):
    - Conv3d(in â†’ planes, 1Ã—1Ã—1, stride) + norm

    è¾“å‡º: relu(ä¸»è·¯å¾„ + æ®‹å·®è·¯å¾„)

    å‚æ•°é‡å¯¹æ¯”:
    - æ ‡å‡†3Ã—3Ã—3 conv: 27 Ã— in Ã— out å‚æ•°
    - Bottleneck: (1Ã—inÃ—mid + 27Ã—midÃ—mid + 1Ã—midÃ—out)
      å½“mid = out//4æ—¶ï¼Œå‚æ•°é‡çº¦ä¸ºæ ‡å‡†çš„1/4
    """
```

**ä¸Šä¸‹æ–‡ç¼–ç å™¨: `ContextEncoder`**

```python
class ContextEncoder(nn.Module):
    """
    ä¸“é—¨ä¸ºå‚è€ƒä½“vol0æå–ä¸Šä¸‹æ–‡ç‰¹å¾

    å¤ç”¨BasicEncoderï¼Œä½†è¾“å‡ºåŒé€šé“:
    - hidden: (B, hidden_dim, H/8, W/8, D/8)  åˆå§‹åŒ–GRUéšè—çŠ¶æ€
    - context: (B, context_dim, H/8, W/8, D/8)  é™æ€ä¸Šä¸‹æ–‡ç‰¹å¾

    å®ç°:
    features = BasicEncoder(vol0)  # è¾“å‡º: (B, hidden+context, ...)
    net, context = torch.split(features, [hidden_dim, context_dim], dim=1)
    net = tanh(net)      # GRU hiddenç”¨tanhæ¿€æ´»
    context = relu(context)  # contextç”¨reluæ¿€æ´»

    ä¸ºä»€ä¹ˆéœ€è¦context?
    - æä¾›vol0çš„å…¨å±€/å±€éƒ¨ç»“æ„ä¿¡æ¯
    - åœ¨è¿­ä»£æ›´æ–°ä¸­ä¿æŒä¸å˜ï¼Œä½œä¸º"è®°å¿†"
    - å¸®åŠ©GRUæ›´å¥½åœ°æ•´åˆç›¸å…³æ€§å’Œè¿åŠ¨ä¿¡æ¯
    """
```

---

### 1.3 `corr.py` - ç›¸å…³æ€§è®¡ç®—

**æ ¸å¿ƒç±»: `CorrBlock`**

```python
class CorrBlock:
    """
    ç›¸å…³æ€§é‡‘å­—å¡”æ„å»ºä¸æŸ¥æ‰¾

    åˆå§‹åŒ–é˜¶æ®µ:
    ==========
    def __init__(fmap0, fmap1, num_levels=4, radius=4):
        # fmap0, fmap1: (B, C, H, W, D) ç‰¹å¾å›¾

        æ­¥éª¤1: è®¡ç®—å…¨å¯¹ç›¸å…³æ€§
        -------------------
        B, C, H, W, D = fmap0.shape

        # å±•å¹³ç©ºé—´ç»´åº¦
        fmap0_flat = fmap0.view(B, C, H*W*D)  # (B, C, N) where N=HÃ—WÃ—D
        fmap1_flat = fmap1.view(B, C, H*W*D)

        # å…¨å¯¹å†…ç§¯ (è¿™æ˜¯æœ€è€—å†…å­˜çš„æ­¥éª¤ï¼)
        corr = torch.matmul(fmap0_flat.transpose(1,2), fmap1_flat)
        # corr: (B, N, N) = (B, H*W*D, H*W*D)

        # é‡å¡‘æˆ6D
        corr = corr.view(B, H, W, D, H, W, D)
        # ç»´åº¦å«ä¹‰: [batch, h_0, w_0, d_0, h_1, w_1, d_1]
        # corr[b, h, w, d, :, :, :] = fmap0åœ¨(h,w,d)ä½ç½®ä¸fmap1æ‰€æœ‰ä½ç½®çš„ç›¸ä¼¼åº¦

        æ­¥éª¤2: æ„å»ºé‡‘å­—å¡”
        ----------------
        pyramid = [corr]  # Level 0: åŸå§‹åˆ†è¾¨ç‡

        for level in range(1, num_levels):
            # å¯¹å3ä¸ªç»´åº¦(h_1, w_1, d_1)åšå¹³å‡æ± åŒ–
            corr = F.avg_pool3d(corr, 2, stride=2)
            pyramid.append(corr)

        é‡‘å­—å¡”ç»“æ„ (ä»¥32Ã—32Ã—32ç‰¹å¾å›¾ä¸ºä¾‹):
        - Level 0: (B, 32, 32, 32, 32, 32, 32)  åŸå§‹
        - Level 1: (B, 32, 32, 32, 16, 16, 16)  1/2
        - Level 2: (B, 32, 32, 32, 8, 8, 8)     1/4
        - Level 3: (B, 32, 32, 32, 4, 4, 4)     1/8

        å†…å­˜å ç”¨:
        Level 0: 32^6 Ã— 4B = 4.3 GB (float32)
        Level 1: 32^3 Ã— 16^3 Ã— 4B = 0.54 GB
        Level 2: 32^3 Ã— 8^3 Ã— 4B = 67 MB
        Level 3: 32^3 Ã— 4^3 Ã— 4B = 8.4 MB
        æ€»è®¡: ~4.9 GB (Level 0å ä¸»å¯¼)


    æŸ¥æ‰¾é˜¶æ®µ (æ¯æ¬¡GRUè¿­ä»£è°ƒç”¨):
    =======================
    def __call__(coords):
        # coords: (B, 3, H, W, D) å½“å‰flowåæ ‡

        out = []
        for level, corr in enumerate(self.pyramid):
            # åœ¨å½“å‰levelæå–radiusé‚»åŸŸ
            delta = torch.arange(-radius, radius+1)  # [-4, -3, ..., 3, 4]

            # è®¡ç®—é‡‡æ ·ä½ç½® (ä»¥level 0ä¸ºä¾‹)
            centroid = coords / (2 ** level)  # æ ¹æ®é‡‘å­—å¡”å±‚çº§ç¼©æ”¾åæ ‡

            # æ„å»º9Ã—9Ã—9é‚»åŸŸ
            for dz in delta:
                for dy in delta:
                    for dx in delta:
                        sample_coords = centroid + (dz, dy, dx)
                        # ä½¿ç”¨åŒçº¿æ€§æ’å€¼é‡‡æ ·
                        sample = grid_sample(corr, sample_coords)
                        out.append(sample)

        # æ‹¼æ¥æ‰€æœ‰å±‚çº§å’Œé‚»åŸŸ
        corr_features = torch.cat(out, dim=1)
        # è¾“å‡ºå½¢çŠ¶: (B, num_levels Ã— (2r+1)^3, H, W, D)
        #         = (B, 4 Ã— 9^3, H, W, D)
        #         = (B, 2916, H, W, D)

        è¿”å›: corr_features

    ä¸ºä»€ä¹ˆä½¿ç”¨é‡‘å­—å¡”?
    ================
    1. å¤šå°ºåº¦æœç´¢:
       - Level 0 (åŸå§‹): ç²¾ç¡®åŒ¹é…ï¼Œæœç´¢èŒƒå›´ Â±4 voxels
       - Level 1 (1/2): ä¸­ç­‰èŒƒå›´ï¼Œæœç´¢èŒƒå›´ Â±8 voxels
       - Level 2 (1/4): å¤§èŒƒå›´ï¼Œæœç´¢èŒƒå›´ Â±16 voxels
       - Level 3 (1/8): è¶…å¤§èŒƒå›´ï¼Œæœç´¢èŒƒå›´ Â±32 voxels

    2. è®¡ç®—æ•ˆç‡:
       - åªé‡‡æ ·åŠå¾„å†…çš„9Ã—9Ã—9é‚»åŸŸï¼Œè€Œéå…¨éƒ¨32Ã—32Ã—32
       - æ¯ä¸ªä½ç½®åªéœ€81Ã—4=324æ¬¡é‡‡æ ·ï¼Œè€Œé32768æ¬¡

    3. æ¸è¿›ä¼˜åŒ–:
       - ç²—ç•¥å±‚çº§å¿«é€Ÿé”å®šå¤§è‡´ä½ç½®
       - ç²¾ç»†å±‚çº§é€æ­¥refineåˆ°äºšä½“ç´ ç²¾åº¦
    """
```

**è¾…åŠ©å‡½æ•°**

```python
def coords_grid_3d(B, H, W, D, device):
    """
    åˆ›å»º3Dåæ ‡ç½‘æ ¼

    è¾“å‡º: (B, 3, H, W, D)
    coords[b, 0, h, w, d] = h  (yåæ ‡)
    coords[b, 1, h, w, d] = w  (xåæ ‡)
    coords[b, 2, h, w, d] = d  (zåæ ‡)

    ç”¨é€”: flowçš„åˆå§‹åŒ–
    flow = coords1 - coords0
    å½“coords1 = coords0æ—¶ï¼Œflowå…¨ä¸º0
    """

def upflow_3d(flow, target_shape):
    """
    å°†1/8åˆ†è¾¨ç‡çš„flowä¸Šé‡‡æ ·åˆ°åŸåˆ†è¾¨ç‡

    è¾“å…¥: (B, 3, H/8, W/8, D/8)
    è¾“å‡º: (B, 3, H, W, D)

    å®ç°:
    1. ä¸‰çº¿æ€§æ’å€¼ä¸Šé‡‡æ ·ç©ºé—´ç»´åº¦ Ã— 8
    2. flowå€¼åŒæ—¶ç¼©æ”¾ Ã— 8 (å› ä¸ºåŸåˆ†è¾¨ç‡ä¸‹çš„ä½ç§»æ˜¯8å€)

    ç¤ºä¾‹:
    - ç‰¹å¾ç©ºé—´ä½ç§»1 voxel â†’ åŸç©ºé—´ä½ç§»8 voxels
    """
```

---

### 1.4 `update.py` - GRUæ›´æ–°æ¨¡å—

**æ•´ä½“ç»“æ„**

```
è¾“å…¥: net, context, corr, flow
  â”‚
  â”œâ”€> [MotionEncoder]
  â”‚   è¾“å…¥: flow (B,3,H,W,D), corr (B,2916,H,W,D)
  â”‚   å¤„ç†:
  â”‚   - å¯¹corråš1Ã—1 conv â†’ (B, 96, H, W, D)
  â”‚   - å¯¹flowåš7Ã—7 + 3Ã—3 conv â†’ (B, 32, H, W, D)
  â”‚   - æ‹¼æ¥: [96+32, flow] â†’ (B, 131, H, W, D)
  â”‚   è¾“å‡º: motion_features (åŒ…å«flowæœ¬èº«ï¼Œä¾¿äºæ®‹å·®è¿æ¥)
  â”‚
  â”œâ”€> [æ‹¼æ¥è¾“å…¥]
  â”‚   inp = [context, motion_features]
  â”‚   inp: (B, 64+131=195, H, W, D)
  â”‚
  â”œâ”€> [ConvGRU3D / SepConvGRU3D]
  â”‚   è¾“å…¥: net (B,96,H,W,D), inp (B,195,H,W,D)
  â”‚   GRUæ ‡å‡†å…¬å¼ (ç”¨3Då·ç§¯å®ç°):
  â”‚   z = Ïƒ(conv([net, inp]))     # update gate
  â”‚   r = Ïƒ(conv([net, inp]))     # reset gate
  â”‚   q = tanh(conv([r*net, inp])) # candidate
  â”‚   net_new = (1-z)*net + z*q
  â”‚   è¾“å‡º: net_new (B, 96, H, W, D)
  â”‚
  â””â”€> [FlowHead]
      è¾“å…¥: net_new (B, 96, H, W, D)
      å¤„ç†:
      - Conv3d(96 â†’ 128, 3Ã—3Ã—3) + relu
      - Conv3d(128 â†’ 3, 3Ã—3Ã—3)  # é¢„æµ‹3ä¸ªæ–¹å‘çš„delta
      è¾“å‡º: delta_flow (B, 3, H, W, D)

è¾“å‡º: net_new, delta_flow
```

**æ ¸å¿ƒç±»: `ConvGRU3D`**

```python
class ConvGRU3D(nn.Module):
    """
    3Då·ç§¯GRU

    æ ‡å‡†GRUå…¬å¼:
    h_t = (1 - z_t) * h_{t-1} + z_t * q_t

    å…¶ä¸­:
    z_t = sigmoid(W_z * [h_{t-1}, x_t])  # update gate
    r_t = sigmoid(W_r * [h_{t-1}, x_t])  # reset gate
    q_t = tanh(W_q * [r_t * h_{t-1}, x_t])  # candidate

    åœ¨RAFTä¸­:
    - h (net): GRUéšè—çŠ¶æ€ (B, 96, H, W, D)
    - x (inp): è¾“å…¥ = [context, motion] (B, 195, H, W, D)
    - W_*: 3Då·ç§¯å±‚ (kernel=3Ã—3Ã—3)

    ä½œç”¨:
    - æ•´åˆå†å²ä¿¡æ¯ (net) å’Œå½“å‰è§‚æµ‹ (corr, flow)
    - é€æ­¥refine flowä¼°è®¡
    - ä¿æŒæ—¶åºä¸€è‡´æ€§
    """
```

**ä¼˜åŒ–ç‰ˆæœ¬: `SepConvGRU3D`**

```python
class SepConvGRU3D(nn.Module):
    """
    å¯åˆ†ç¦»3Då·ç§¯GRU

    æ ‡å‡†3Ã—3Ã—3å·ç§¯å‚æ•°é‡: 27 Ã— C_in Ã— C_out
    å¯åˆ†ç¦»å·ç§¯å‚æ•°é‡: (5 + 5 + 5) Ã— C_in Ã— C_out = 15 Ã— C_in Ã— C_out

    å®ç°:
    - å°†3Ã—3Ã—3å·ç§¯åˆ†è§£ä¸º: 5Ã—1Ã—1 + 1Ã—5Ã—1 + 1Ã—1Ã—5
    - ä¾æ¬¡å¤„ç†é«˜åº¦ã€å®½åº¦ã€æ·±åº¦ç»´åº¦
    - èŠ‚çœå‚æ•°ï¼Œä½†ä¿æŒè¶³å¤Ÿçš„æ„Ÿå—é‡

    GRUæ¯ä¸ªgateéƒ½éœ€è¦3ä¸ªå·ç§¯ (z, r, q)
    æ€»å…±: 3ä¸ªgate Ã— 3ä¸ªç»´åº¦ = 9ä¸ªå·ç§¯å±‚
    """
```

**MotionEncoder**

```python
class MotionEncoder(nn.Module):
    """
    ç¼–ç è¿åŠ¨ä¿¡æ¯

    è¾“å…¥:
    - flow: å½“å‰flowä¼°è®¡ (B, 3, H, W, D)
    - corr: ç›¸å…³æ€§ç‰¹å¾ (B, 2916, H, W, D)

    å¤„ç†:
    1. ç›¸å…³æ€§åˆ†æ”¯:
       corr â†’ Conv1Ã—1(2916 â†’ 96) â†’ relu
       å‹ç¼©é«˜ç»´ç›¸å…³æ€§ç‰¹å¾

    2. Flowåˆ†æ”¯:
       flow â†’ Conv7Ã—7(3 â†’ 64) â†’ relu â†’ Conv3Ã—3(64 â†’ 32) â†’ relu
       æå–flowçš„ç©ºé—´æ¨¡å¼

    3. èåˆ:
       [cor_feat(96), flo_feat(32)] â†’ concat(128) â†’ Conv3Ã—3(128 â†’ 80) â†’ relu
       â†’ [out(80), flow(3)] â†’ concat(83)

    è¾“å‡º: (B, 83, H, W, D)
    ä¿ç•™åŸå§‹flowå€¼ä¾¿äºæ®‹å·®å­¦ä¹ 
    """
```

---

### 1.5 `utils.py` - å·¥å…·å‡½æ•°

```python
def warp_volume_3d(volume, flow):
    """
    æ ¹æ®flowå˜å½¢ä½“æ•°æ®

    è¾“å…¥:
    - volume: (B, C, H, W, D) å¾…å˜å½¢çš„ä½“
    - flow: (B, 3, H, W, D) ä½ç§»åœº
      flow[:, 0] = dy (Hæ–¹å‘ä½ç§»)
      flow[:, 1] = dx (Wæ–¹å‘ä½ç§»)
      flow[:, 2] = dz (Dæ–¹å‘ä½ç§»)

    æµç¨‹:
    1. åˆ›å»ºåŸºç¡€ç½‘æ ¼: grid[h,w,d] = (h, w, d)
    2. åŠ ä¸Šä½ç§»: sample_grid = grid + flow
    3. ä½¿ç”¨grid_sampleè¿›è¡Œä¸‰çº¿æ€§æ’å€¼é‡‡æ ·

    è¾“å‡º: å˜å½¢åçš„ä½“ (B, C, H, W, D)

    ç”¨é€”:
    - è®­ç»ƒæ—¶çš„photometric loss
    - å¯è§†åŒ–flowæ•ˆæœ
    - æµ‹è¯•flowå‡†ç¡®æ€§
    """

def compute_flow_magnitude(flow):
    """
    è®¡ç®—flowçš„å¹…åº¦

    è¾“å…¥: (B, 3, H, W, D)
    è¾“å‡º: (B, 1, H, W, D)

    å…¬å¼: mag = sqrt(dy^2 + dx^2 + dz^2)

    ç”¨äº:
    - å¯è§†åŒ–ä½ç§»å¤§å°
    - ä½œä¸ºæƒé‡ (ä¾‹å¦‚é®ç½©å°ä½ç§»åŒºåŸŸ)
    """

def flow_to_color_3d(flow, slice_axis=0, slice_idx=None):
    """
    å°†3D flowå¯è§†åŒ–ä¸º2Då½©è‰²å›¾

    æµç¨‹:
    1. æå–æŸä¸ªè½´çš„åˆ‡ç‰‡ (ä¾‹å¦‚z=ä¸­é—´å±‚)
    2. é€‰æ‹©2ä¸ªflowåˆ†é‡ (ä¾‹å¦‚dx, dy)
    3. HSVç¼–ç :
       - Hue (è‰²è°ƒ): flowçš„æ–¹å‘
       - Saturation (é¥±å’Œåº¦): flowçš„å¹…åº¦
       - Value (æ˜åº¦): å›ºå®šä¸º1
    4. è½¬æ¢ä¸ºRGB

    ç”¨é€”: è°ƒè¯•å’Œè®ºæ–‡æ’å›¾
    """
```

---

## 2. æ•°æ®åŠ è½½ (`src/data/`)

### 2.1 `dataset.py` - æ•°æ®é›†ç±»

**`VolumePairDataset`**

```python
class VolumePairDataset(Dataset):
    """
    è®­ç»ƒæ•°æ®é›†

    ç›®å½•ç»“æ„è¦æ±‚:
    root_dir/
      vol0/
        sample_001.npy  # å‚è€ƒä½“
        sample_002.npy
        ...
      vol1/
        sample_001.npy  # å½¢å˜ä½“
        sample_002.npy
        ...
      flow/
        sample_001.npy  # ground truth flow (3, H, W, D)
        sample_002.npy
        ...

    åŠŸèƒ½:
    1. åŠ è½½åŒ¹é…çš„vol0/vol1/flowä¸‰å…ƒç»„
    2. å¯é€‰: éšæœºè£å‰ªpatch (ä¾‹å¦‚64Ã—64Ã—64)
    3. å¯é€‰: æ•°æ®å¢å¼º (ç¿»è½¬ã€æ—‹è½¬)

    æ•°æ®å¢å¼ºç»†èŠ‚:
    - éšæœºç¿»è½¬ (x, y, zè½´): éœ€åŒæ—¶ç¿»è½¬flowå¯¹åº”åˆ†é‡ç¬¦å·
    - éšæœº90åº¦æ—‹è½¬ (xyå¹³é¢): éœ€æ—‹è½¬flowå‘é‡

    ç¤ºä¾‹: æ²¿yè½´ç¿»è½¬
    vol0 = np.flip(vol0, axis=0)
    vol1 = np.flip(vol1, axis=0)
    flow = np.flip(flow, axis=1)  # ç¿»è½¬ç©ºé—´
    flow[0] = -flow[0]  # ç¿»è½¬dyåˆ†é‡ç¬¦å·

    __getitem__ è¿”å›:
    {
        'vol0': (1, H, W, D),
        'vol1': (1, H, W, D),
        'flow': (3, H, W, D),
        'filename': str
    }
    """
```

**`InferenceDataset`**

```python
class InferenceDataset(Dataset):
    """
    æ¨ç†æ•°æ®é›†

    ç‰¹ç‚¹:
    - ä¸éœ€è¦ground truth flow
    - æ”¯æŒå¤šç§æ ¼å¼: .npy, .tif, .h5
    - ä¸åšå¢å¼ºæˆ–è£å‰ª

    ç”¨é€”:
    - å¯¹æ–°çš„ã€æœªæ ‡æ³¨çš„æ•°æ®è¿›è¡Œæ¨ç†
    """
```

---

### 2.2 `synthetic.py` - åˆæˆæ•°æ®ç”Ÿæˆ

```python
class SyntheticFlowGenerator:
    """
    ç”Ÿæˆåˆæˆä½ç§»åœºç”¨äºè®­ç»ƒ

    æ”¯æŒçš„å˜å½¢ç±»å‹:
    ===============

    1. Translation (å¹³ç§»)
    - å…¨ä½“å‡åŒ€ä½ç§»
    - flow[0] = ty, flow[1] = tx, flow[2] = tz
    - å‚æ•°: max_translation (é»˜è®¤10 voxels)

    2. Rotation (æ—‹è½¬)
    - ç»•ä½“ä¸­å¿ƒæ—‹è½¬
    - ä½¿ç”¨æ—‹è½¬çŸ©é˜µR = Rz @ Ry @ Rx
    - å‚æ•°: max_rotation_deg (é»˜è®¤5åº¦)
    - flow = R @ coords - coords

    3. Affine (ä»¿å°„)
    - ç¼©æ”¾ + å‰ªåˆ‡ + å¹³ç§»
    - å‚æ•°: max_scale=0.05 (Â±5%), max_shear=0.02
    - é€‚åˆæ¨¡æ‹Ÿææ–™å˜å½¢

    4. Polynomial (å¤šé¡¹å¼)
    - å…‰æ»‘çš„éçº¿æ€§å˜å½¢
    - flow_x = Î£ c_ijk Ã— y^i Ã— x^j Ã— z^k
    - å‚æ•°: poly_degree=3, poly_amplitude=3.0
    - é€‚åˆæ¨¡æ‹Ÿå¤æ‚å½¢å˜

    5. Smooth Random (å…‰æ»‘éšæœº)
    - é«˜æ–¯æ»¤æ³¢çš„éšæœºåœº
    - å‚æ•°: sigma (10-30), amplitude (1-5)
    - é€‚åˆæ¨¡æ‹Ÿå±€éƒ¨ä¸è§„åˆ™å˜å½¢

    6. Combined (ç»„åˆ)
    - éšæœºç»„åˆ2-3ç§ç±»å‹
    - æƒé‡éšæœº

    ä½¿ç”¨ç¤ºä¾‹:
    =========
    generator = SyntheticFlowGenerator(seed=42)

    # ç”Ÿæˆéšæœºflow
    flow = generator.generate(shape=(64, 64, 64))

    # ç”Ÿæˆç‰¹å®šç±»å‹
    flow = generator.generate(shape=(64, 64, 64), flow_type='rotation')

    # ç”Ÿæˆè®­ç»ƒå¯¹
    vol0 = ...  # åŠ è½½å‚è€ƒä½“
    vol0, vol1, flow = generator.generate_pair(vol0)
    # vol1 = warp(vol0, flow)
    """

    def warp_volume(volume, flow):
        """
        åº”ç”¨flowå˜å½¢volume

        ä½¿ç”¨scipy.ndimage.map_coordinatesè¿›è¡Œæ’å€¼
        - order=0: æœ€è¿‘é‚»
        - order=1: çº¿æ€§ (é»˜è®¤)
        - order=3: ä¸‰æ¬¡

        è¾¹ç•Œå¤„ç†: mode='constant', cval=0 (å¡«å……0)
        """
```

---

## 3. è®­ç»ƒæ¨¡å— (`src/training/`)

### 3.1 `loss.py` - æŸå¤±å‡½æ•°

**`SequenceLoss`**

```python
class SequenceLoss(nn.Module):
    """
    åºåˆ—ç›‘ç£æŸå¤±

    ç”±äºRAFTè¾“å‡º12æ¬¡è¿­ä»£çš„flowé¢„æµ‹ï¼Œéœ€è¦å¯¹æ¯æ¬¡éƒ½è®¡ç®—æŸå¤±
    ä½†åæœŸè¿­ä»£åº”è¯¥æ›´å‡†ç¡®ï¼Œç»™äºˆæ›´é«˜æƒé‡

    å…¬å¼:
    ====
    loss = Î£_{i=1}^{12} gamma^(12-i) Ã— ||flow_pred_i - flow_gt||_2

    å…¶ä¸­:
    - gamma âˆˆ (0, 1): è¡°å‡å› å­ (é»˜è®¤0.8)
    - gamma^(12-i): æƒé‡éšè¿­ä»£é€’å¢
      - iter 1: gamma^11 = 0.8^11 â‰ˆ 0.086
      - iter 6: gamma^6 = 0.8^6 â‰ˆ 0.262
      - iter 12: gamma^0 = 1.0  (æœ€å¤§æƒé‡)

    ä¸ºä»€ä¹ˆä½¿ç”¨åºåˆ—æŸå¤±?
    =================
    1. æ¢¯åº¦ç¨³å®š: æ—©æœŸè¿­ä»£ä¹Ÿèƒ½æ”¶åˆ°æ¢¯åº¦ä¿¡å·
    2. æ”¶æ•›åŠ é€Ÿ: ä¸å¿…ç­‰åˆ°æœ€åä¸€æ¬¡è¿­ä»£æ‰å­¦ä¹ 
    3. é²æ£’æ€§: å³ä½¿æœ€åä¸€æ¬¡è¿­ä»£å¤±è´¥ï¼Œå‰é¢çš„ä»æœ‰ç”¨

    ä»£ç :
    ====
    def forward(flow_preds, flow_gt):
        # flow_preds: list of 12ä¸ª(B, 3, H, W, D)
        # flow_gt: (B, 3, H, W, D)

        n_predictions = len(flow_preds)  # 12
        loss = 0

        for i, flow_pred in enumerate(flow_preds):
            # è®¡ç®—å½“å‰è¿­ä»£çš„æƒé‡
            i_weight = self.gamma ** (n_predictions - i - 1)

            # L2æŸå¤±
            i_loss = (flow_pred - flow_gt).abs().mean()

            loss += i_weight * i_loss

        return loss
    """
```

**å…¶ä»–å¯é€‰æŸå¤±**

```python
class SmoothLoss(nn.Module):
    """
    å¹³æ»‘æ­£åˆ™åŒ– (å¯é€‰)

    é¼“åŠ±flowåœ¨ç©ºé—´ä¸Šå¹³æ»‘

    å…¬å¼:
    loss_smooth = Î£ |âˆ‡flow|^2

    å®ç°:
    dx = flow[:,:,1:,:,:] - flow[:,:,:-1,:,:]  # xæ–¹å‘æ¢¯åº¦
    dy = flow[:,:,:,1:,:] - flow[:,:,:,:-1,:]  # yæ–¹å‘æ¢¯åº¦
    dz = flow[:,:,:,:,1:] - flow[:,:,:,:,:-1]  # zæ–¹å‘æ¢¯åº¦
    loss = (dx^2 + dy^2 + dz^2).mean()

    æ³¨æ„:
    - å¯¹çœŸå®DVCæ•°æ®å¯èƒ½è¿‡åº¦å¹³æ»‘
    - é€‚åˆç”¨äºåˆæˆæ•°æ®çš„é¢„è®­ç»ƒ
    - æƒé‡ç³»æ•°é€šå¸¸å¾ˆå° (0.001-0.01)
    """
```

---

### 3.2 `trainer.py` - è®­ç»ƒç®¡ç†å™¨

```python
class Trainer:
    """
    è®­ç»ƒå¾ªç¯å°è£…

    åˆå§‹åŒ–:
    ======
    def __init__(model, train_loader, val_loader, output_dir, config):
        # è®¾ç½®è®¾å¤‡
        self.device = torch.device('cuda' if available else 'cpu')

        # ä¼˜åŒ–å™¨: AdamW
        self.optimizer = AdamW(
            model.parameters(),
            lr=4e-4,
            weight_decay=1e-4
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨: OneCycleLR
        # - å‰5%: warm-up
        # - ä¸­é—´: çº¿æ€§é€€ç«åˆ°0
        total_steps = len(train_loader) * epochs
        self.scheduler = OneCycleLR(
            optimizer,
            max_lr=4e-4,
            total_steps=total_steps,
            pct_start=0.05
        )

        # æŸå¤±å‡½æ•°
        self.criterion = SequenceLoss(gamma=0.8)

        # æ··åˆç²¾åº¦ (å¯é€‰)
        self.scaler = torch.cuda.amp.GradScaler()

    è®­ç»ƒä¸€ä¸ªepoch:
    =============
    def train_epoch():
        model.train()

        for batch in train_loader:
            vol0 = batch['vol0'].to(device)
            vol1 = batch['vol1'].to(device)
            gt_flow = batch['flow'].to(device)

            optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            with torch.cuda.amp.autocast():  # æ··åˆç²¾åº¦
                flow_preds = model(vol0, vol1, iters=12)
                loss = criterion(flow_preds, gt_flow)

            # åå‘ä¼ æ’­
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)

            # æ¢¯åº¦è£å‰ª (é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸)
            torch.nn.utils.clip_grad_norm_(
                model.parameters(),
                max_norm=1.0
            )

            scaler.step(optimizer)
            scaler.update()
            scheduler.step()  # æ¯ä¸ªbatchæ›´æ–°lr

        return avg_loss

    éªŒè¯:
    ====
    @torch.no_grad()
    def validate():
        model.eval()

        for batch in val_loader:
            vol0, vol1, gt_flow = ...
            flow_preds = model(vol0, vol1, iters=12)

            # è®¡ç®—åºåˆ—æŸå¤±
            loss = criterion(flow_preds, gt_flow)

            # è®¡ç®—EPE (End-Point Error)
            final_flow = flow_preds[-1]
            epe = sqrt(sum((final_flow - gt_flow)^2, dim=1)).mean()

        return avg_loss, avg_epe

    ä¿å­˜checkpoint:
    ==============
    def save_checkpoint(filename, is_best=False):
        checkpoint = {
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'epoch': epoch,
            'best_val_loss': best_val_loss,
            'config': config
        }
        torch.save(checkpoint, filename)

        if is_best:
            # é¢å¤–ä¿å­˜æœ€ä½³æ¨¡å‹
            torch.save(checkpoint, 'best_model.pth')
    """
```

---

## 4. æ¨ç†è„šæœ¬ (`scripts/`)

### 4.1 `train.py` - è®­ç»ƒå…¥å£

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/train.py \
    --data_dir data/train \
    --output_dir results/exp1 \
    --epochs 100 \
    --batch_size 2 \
    --patch_size 64 64 64 \
    --augment

# è‡ªå®šä¹‰æ¨¡å‹å‚æ•°
python scripts/train.py \
    --data_dir data/train \
    --corr_levels 2 \
    --corr_radius 4 \
    --iters 12 \
    --mixed_precision

# ä»checkpointæ¢å¤
python scripts/train.py \
    --data_dir data/train \
    --resume results/exp1/latest.pth
```

**æµç¨‹**

```python
def main():
    # 1. åˆ›å»ºæ¨¡å‹
    config = RAFTDVCConfig(
        corr_levels=args.corr_levels,
        corr_radius=args.corr_radius,
        iters=args.iters
    )
    model = RAFTDVC(config)

    # 2. åˆ›å»ºæ•°æ®é›†
    dataset = VolumePairDataset(
        root_dir=args.data_dir,
        patch_size=(64, 64, 64),
        augment=True
    )

    # 3. åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    train_set, val_set = random_split(dataset, [0.9, 0.1])

    # 4. åˆ›å»ºTrainer
    trainer = Trainer(
        model=model,
        train_loader=DataLoader(train_set, batch_size=2),
        val_loader=DataLoader(val_set, batch_size=1),
        output_dir='results/',
        config={'epochs': 100, 'lr': 4e-4, ...}
    )

    # 5. è®­ç»ƒ
    trainer.train()
```

---

### 4.2 `infer.py` - æ¨ç†å…¥å£

```bash
# å•å¯¹æ¨ç†
python scripts/infer.py \
    --checkpoint checkpoints/best_model.pth \
    --vol0 data/test/ref.npy \
    --vol1 data/test/def.npy \
    --output results/flow.npy \
    --iters 24

# ä½¿ç”¨æ»‘åŠ¨çª—å£ (å¤§ä½“æ•°æ®)
python scripts/infer.py \
    --checkpoint checkpoints/best_model.pth \
    --vol0 data/large_vol0.npy \
    --vol1 data/large_vol1.npy \
    --patch_size 64 64 64 \
    --overlap 0.5 \
    --output results/flow_large.npy

# æ‰¹é‡æ¨ç†
python scripts/infer.py \
    --checkpoint checkpoints/best_model.pth \
    --data_dir data/test \
    --output_dir results/test_inference
```

**æ»‘åŠ¨çª—å£æ¨ç† (å¤„ç†å¤§ä½“æ•°æ®)**

```python
def infer_sliding_window(model, vol0, vol1, patch_size, overlap):
    """
    åˆ†å—å¤„ç†å¤§ä½“æ•°æ®

    æµç¨‹:
    ====
    1. è®¡ç®—tileä½ç½®
    -----------
    H, W, D = vol0.shape
    ph, pw, pd = patch_size  # ä¾‹å¦‚64Ã—64Ã—64
    step = patch_size * (1 - overlap)  # ä¾‹å¦‚overlap=0.5 â†’ step=32

    positions = []
    for h in range(0, H, step):
        for w in range(0, W, step):
            for d in range(0, D, step):
                positions.append((h, w, d))

    2. åˆ›å»ºæƒé‡å›¾ (ç”¨äºæ··åˆ)
    --------------------
    # é«˜æ–¯æƒé‡: ä¸­å¿ƒæƒé‡é«˜ï¼Œè¾¹ç¼˜æƒé‡ä½
    sigma = min(patch_size) / 4
    y, x, z = np.meshgrid(...)
    weight = exp(-(y^2 + x^2 + z^2) / (2*sigma^2))

    3. é€å—æ¨ç†
    ----------
    flow_sum = zeros(3, H, W, D)
    weight_sum = zeros(1, H, W, D)

    for (h, w, d) in positions:
        # æå–patch
        patch0 = vol0[h:h+ph, w:w+pw, d:d+pd]
        patch1 = vol1[h:h+ph, w:w+pw, d:d+pd]

        # æ¨ç†
        flow_patch = model(patch0, patch1)

        # åŠ æƒç´¯åŠ 
        flow_sum[:, h:h+ph, w:w+pw, d:d+pd] += flow_patch * weight
        weight_sum[:, h:h+ph, w:w+pw, d:d+pd] += weight

    4. å½’ä¸€åŒ–
    --------
    flow = flow_sum / (weight_sum + epsilon)

    è¿”å›: flow (3, H, W, D)

    ä¸ºä»€ä¹ˆä½¿ç”¨åŠ æƒæ··åˆ?
    ==================
    - é¿å…å—è¾¹ç•Œçš„æ¥ç¼
    - overlapåŒºåŸŸæœ‰å¤šä¸ªé¢„æµ‹ï¼ŒåŠ æƒå¹³å‡æ›´ç¨³å®š
    - é«˜æ–¯æƒé‡è®©patchä¸­å¿ƒåŒºåŸŸ(æ›´å¯é )è´¡çŒ®æ›´å¤š
    """
```

---

## 5. é…ç½®æ–‡ä»¶ (`configs/`)

### `configs/training/default.yaml`

```yaml
# æ•°æ®é…ç½®
data:
  train_dataset: "data/train"
  val_dataset: "data/val"
  batch_size: 2                # 3Dæ•°æ®å¾ˆå¤§ï¼Œbatché€šå¸¸å¾ˆå°
  num_workers: 4
  volume_size: [64, 64, 64]   # patchå¤§å°

# æ¨¡å‹é…ç½®
model:
  input_channels: 1
  feature_dim: 128
  hidden_dim: 96
  context_dim: 64
  corr_levels: 4               # é‡‘å­—å¡”å±‚æ•°
  corr_radius: 4               # æŸ¥æ‰¾åŠå¾„
  iters: 12                    # è¿­ä»£æ¬¡æ•°

# è®­ç»ƒé…ç½®
training:
  epochs: 100
  learning_rate: 0.0001
  weight_decay: 0.0001
  grad_clip: 1.0               # æ¢¯åº¦è£å‰ªé˜ˆå€¼
  mixed_precision: true        # æ··åˆç²¾åº¦è®­ç»ƒ

# ä¼˜åŒ–å™¨
optimizer:
  type: "AdamW"
  betas: [0.9, 0.999]

# å­¦ä¹ ç‡è°ƒåº¦
scheduler:
  type: "OneCycleLR"
  max_lr: 0.0004
  pct_start: 0.05              # warm-upé˜¶æ®µå æ¯”
  anneal_strategy: "cos"       # ä½™å¼¦é€€ç«

# æŸå¤±æƒé‡
loss:
  gamma: 0.8                   # åºåˆ—æŸå¤±è¡°å‡

# Checkpoint
checkpoint:
  save_dir: "checkpoints"
  save_freq: 5                 # æ¯5ä¸ªepochä¿å­˜
  keep_last_n: 3               # åªä¿ç•™æœ€è¿‘3ä¸ª

# æ—¥å¿—
logging:
  log_dir: "logs"
  tensorboard: true
  log_freq: 10                 # æ¯10ä¸ªiterè®°å½•
```

---

## 6. å®Œæ•´è®­ç»ƒæµç¨‹

```
æ­¥éª¤1: å‡†å¤‡æ•°æ®
==============
data/train/
  vol0/
    sample_001.npy  # (64, 64, 64) float32
    sample_002.npy
    ...
  vol1/
    sample_001.npy
    sample_002.npy
    ...
  flow/
    sample_001.npy  # (3, 64, 64, 64) float32
    sample_002.npy
    ...

# å¯é€‰: ä½¿ç”¨synthetic generatorç”Ÿæˆè®­ç»ƒæ•°æ®
from src.data.synthetic import SyntheticFlowGenerator

generator = SyntheticFlowGenerator()
for i in range(1000):
    vol0 = np.random.randn(64, 64, 64)  # æˆ–åŠ è½½çœŸå®æ•°æ®
    vol0, vol1, flow = generator.generate_pair(vol0)
    np.save(f'data/train/vol0/sample_{i:03d}.npy', vol0)
    np.save(f'data/train/vol1/sample_{i:03d}.npy', vol1)
    np.save(f'data/train/flow/sample_{i:03d}.npy', flow)


æ­¥éª¤2: é…ç½®è®­ç»ƒ
==============
# ä¿®æ”¹ configs/training/default.yaml
# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–


æ­¥éª¤3: å¯åŠ¨è®­ç»ƒ
==============
python scripts/train.py \
    --data_dir data/train \
    --output_dir results/exp_baseline \
    --epochs 100 \
    --batch_size 2 \
    --patch_size 64 64 64 \
    --augment \
    --mixed_precision


æ­¥éª¤4: ç›‘æ§è®­ç»ƒ
==============
# æŸ¥çœ‹æ—¥å¿—
tail -f results/exp_baseline/training.log

# ä½¿ç”¨TensorBoard (å¦‚æœå¯ç”¨)
tensorboard --logdir results/exp_baseline/logs

# å…³é”®æŒ‡æ ‡:
# - Train Loss: åº”è¯¥ç¨³å®šä¸‹é™
# - Val Loss: åº”è¯¥ä¸‹é™ä½†å¯èƒ½æ³¢åŠ¨
# - EPE (End-Point Error): åº”è¯¥é€æ¸å‡å°
# - Learning Rate: OneCycleLRä¼šå…ˆä¸Šå‡åä¸‹é™


æ­¥éª¤5: è¯„ä¼°æ¨¡å‹
==============
# åœ¨æµ‹è¯•é›†ä¸Šæ¨ç†
python scripts/infer.py \
    --checkpoint results/exp_baseline/best_model.pth \
    --data_dir data/test \
    --output_dir results/test_predictions \
    --iters 24

# è®¡ç®—è¯„ä¼°æŒ‡æ ‡
python evaluate.py \
    --pred_dir results/test_predictions \
    --gt_dir data/test/flow


æ­¥éª¤6: è¶…å‚æ•°è°ƒä¼˜
================
# å®éªŒ1: å‡å°‘é‡‘å­—å¡”å±‚æ•° (å‚è€ƒRAFT-DIC)
python scripts/train.py \
    --data_dir data/train \
    --output_dir results/exp_p2_r4 \
    --corr_levels 2 \
    --corr_radius 4

# å®éªŒ2: å¢å¤§æŸ¥æ‰¾åŠå¾„
python scripts/train.py \
    --data_dir data/train \
    --output_dir results/exp_p4_r6 \
    --corr_levels 4 \
    --corr_radius 6

# å®éªŒ3: æ›´å¤šè¿­ä»£
python scripts/train.py \
    --data_dir data/train \
    --output_dir results/exp_iter20 \
    --iters 20
```

---

## 7. å®Œæ•´æ¨ç†æµç¨‹

```
åœºæ™¯1: å•å¯¹å°ä½“æ•°æ®æ¨ç†
======================
python scripts/infer.py \
    --checkpoint checkpoints/best_model.pth \
    --vol0 data/test/ref_001.npy \
    --vol1 data/test/def_001.npy \
    --output results/flow_001.npy \
    --iters 24

# è¾“å‡º:
# results/flow_001.npy  (3, H, W, D)


åœºæ™¯2: å¤§ä½“æ•°æ®æ»‘åŠ¨çª—å£æ¨ç†
===========================
# è¾“å…¥: 512Ã—512Ã—512 ä½“æ•°æ®
# GPUå†…å­˜: 12GB
# ç­–ç•¥: 64Ã—64Ã—64 patch, 50% overlap

python scripts/infer.py \
    --checkpoint checkpoints/best_model.pth \
    --vol0 data/large/ref.npy \
    --vol1 data/large/def.npy \
    --patch_size 64 64 64 \
    --overlap 0.5 \
    --output results/flow_large.npy \
    --iters 24

# æ‰§è¡Œæµç¨‹:
# 1. è‡ªåŠ¨è®¡ç®—tileæ•°é‡: ~512 tiles
# 2. é€tileæ¨ç†: [=====>   ] 123/512 (24%)
# 3. é«˜æ–¯åŠ æƒæ··åˆ
# 4. ä¿å­˜å®Œæ•´flow


åœºæ™¯3: æ‰¹é‡æ¨ç†
===============
# ç›®å½•ç»“æ„:
# data/batch/
#   vol0/ (100ä¸ª.npyæ–‡ä»¶)
#   vol1/ (100ä¸ª.npyæ–‡ä»¶)

python scripts/infer.py \
    --checkpoint checkpoints/best_model.pth \
    --data_dir data/batch \
    --output_dir results/batch_inference \
    --patch_size 64 64 64 \
    --overlap 0.5

# è¾“å‡º:
# results/batch_inference/
#   flow_sample_001.npy
#   flow_sample_002.npy
#   ...


åœºæ™¯4: Python APIæ¨ç†
=====================
from src.core import RAFTDVC
import torch
import numpy as np

# åŠ è½½æ¨¡å‹
model, _ = RAFTDVC.load_checkpoint('checkpoints/best_model.pth')
model = model.cuda()
model.eval()

# åŠ è½½æ•°æ®
vol0 = np.load('data/ref.npy')
vol1 = np.load('data/def.npy')

# è½¬tensor
vol0_t = torch.from_numpy(vol0).unsqueeze(0).unsqueeze(0).cuda()
vol1_t = torch.from_numpy(vol1).unsqueeze(0).unsqueeze(0).cuda()

# æ¨ç†
with torch.no_grad():
    _, flow = model(vol0_t, vol1_t, iters=24, test_mode=True)

# åå¤„ç†
flow_np = flow.squeeze().cpu().numpy()  # (3, H, W, D)

# ä¿å­˜
np.save('flow_result.npy', flow_np)

# å¯è§†åŒ– (æŸä¸ªåˆ‡ç‰‡)
from src.core.utils import flow_to_color_3d
flow_rgb = flow_to_color_3d(flow, slice_axis=2, slice_idx=32)
import matplotlib.pyplot as plt
plt.imshow(flow_rgb[0].permute(1, 2, 0).cpu().numpy())
plt.savefig('flow_vis.png')
```

---

## 8. å…³é”®æ€§èƒ½æŒ‡æ ‡

### å†…å­˜å ç”¨ (batch_size=1, patch_size=64)

| ç»„ä»¶ | å½¢çŠ¶ | å†…å­˜ |
|-----|------|------|
| vol0, vol1 | 2 Ã— (1,1,64,64,64) | 2 MB |
| fmap0, fmap1 | 2 Ã— (1,128,8,8,8) | 1 MB |
| 6D correlation | (1,8,8,8,8,8,8) | 8 MB |
| Pyramid Level 1-3 | | 1 MB |
| GRU hidden | (1,96,8,8,8) | 0.4 MB |
| Context | (1,64,8,8,8) | 0.3 MB |
| **æ€»è®¡ (å³°å€¼)** | | **~13 MB** |

> æ³¨: 64Â³ patchæ˜¯å¯è¡Œçš„ã€‚æ›´å¤§çš„patch (å¦‚128Â³) ä¼šå› ä¸º6D correlationçˆ†å†…å­˜ã€‚

### è®­ç»ƒé€Ÿåº¦ (å•GPU, RTX 3090)

- Batch size 2, patch 64Â³, 12 iters
- å‰å‘: ~0.5s
- åå‘: ~1.0s
- **æ€»è®¡: ~1.5s/batch**
- **1 epoch (1000 samples): ~12åˆ†é’Ÿ**

### æ¨ç†é€Ÿåº¦

- å•ä¸ª64Â³ patch: ~0.3s (24 iters)
- 512Â³ä½“æ•°æ® (64Â³patch, 50% overlap): ~512 tiles Ã— 0.3s = **~2.5åˆ†é’Ÿ**

---

## 9. å¸¸è§é—®é¢˜

### Q1: CUDA out of memory

**å¯èƒ½åŸå› :**
1. batch_sizeå¤ªå¤§ â†’ æ”¹ä¸º1
2. patch_sizeå¤ªå¤§ â†’ ä»128Â³é™åˆ°64Â³æˆ–32Â³
3. corr_radiuså¤ªå¤§ â†’ ä»6é™åˆ°4

**è§£å†³æ–¹æ¡ˆ:**
```bash
# å‡å°batchå’Œpatch
python scripts/train.py \
    --batch_size 1 \
    --patch_size 32 32 32

# æˆ–ä½¿ç”¨gradient accumulation
# æ¯4ä¸ªbatchç´¯ç§¯åæ›´æ–°ä¸€æ¬¡ (ç­‰æ•ˆbatch=4)
```

---

### Q2: è®­ç»ƒlossä¸ä¸‹é™

**æ£€æŸ¥æ¸…å•:**
1. æ•°æ®æ˜¯å¦æ­£ç¡®? â†’ å¯è§†åŒ–vol0, vol1, flow
2. å­¦ä¹ ç‡æ˜¯å¦å¤ªå¤§/å¤ªå°? â†’ å°è¯•1e-4åˆ°4e-4
3. æ•°æ®å¢å¼ºæ˜¯å¦ç ´åäº†flow? â†’ å…³é—­`--augment`æµ‹è¯•
4. æ¨¡å‹æ˜¯å¦å¤ªå°/å¤ªå¤§? â†’ æ£€æŸ¥å‚æ•°é‡ (åº”è¯¥~10M)

**è°ƒè¯•æŠ€å·§:**
```python
# åœ¨trainer.pyä¸­æ·»åŠ :
def train_epoch():
    for batch in train_loader:
        ...
        # æ£€æŸ¥lossçš„æ•°é‡çº§
        print(f"Loss: {loss.item():.4f}")

        # æ£€æŸ¥flowé¢„æµ‹çš„èŒƒå›´
        print(f"Flow pred range: [{flow_preds[-1].min():.2f}, {flow_preds[-1].max():.2f}]")
        print(f"Flow GT range: [{gt_flow.min():.2f}, {gt_flow.max():.2f}]")

        # æ£€æŸ¥æ¢¯åº¦
        for name, param in model.named_parameters():
            if param.grad is not None:
                print(f"{name}: grad norm = {param.grad.norm():.4f}")
```

---

### Q3: æ¨ç†ç»“æœæœ‰å—çŠ¶ä¼ªå½±

**åŸå› :** æ»‘åŠ¨çª—å£æ··åˆä¸å¹³æ»‘

**è§£å†³æ–¹æ¡ˆ:**
1. å¢å¤§overlap: `--overlap 0.75`
2. ä½¿ç”¨é«˜æ–¯æƒé‡ (å·²é»˜è®¤)
3. å‡å°patch_size (å¢åŠ overlapåŒºåŸŸå æ¯”)

---

### Q4: å¦‚ä½•ä»volRAFT checkpointè¿ç§»?

```python
# volRAFTå’ŒRAFT-DVCæ¶æ„ç›¸åŒï¼Œå¯ä»¥ç›´æ¥åŠ è½½
# ä½†éœ€è¦ç¡®ä¿configåŒ¹é…

# æ–¹æ³•1: ç›´æ¥åŠ è½½
model = RAFTDVC(config)
checkpoint = torch.load('volraft_weights.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# æ–¹æ³•2: éƒ¨åˆ†åŠ è½½ (å¦‚æœconfigä¸åŒ¹é…)
model = RAFTDVC(new_config)
checkpoint = torch.load('volraft_weights.pth')

# åªåŠ è½½feature encoder (å…±äº«æƒé‡)
fnet_dict = {k: v for k, v in checkpoint['model_state_dict'].items()
             if k.startswith('fnet')}
model.load_state_dict(fnet_dict, strict=False)

# update_blockéœ€è¦é‡æ–°è®­ç»ƒ (å› ä¸ºcorr_levels/radiusä¸åŒ)
```

---

## 10. ä¸‹ä¸€æ­¥: å®ç°åŒæ¨¡å‹æ¨ç†ç®¡é“

å½“å‰ä»£ç åº“å·²å®ç°volRAFTçš„åŸºç¡€æ¶æ„å’Œè®­ç»ƒæµç¨‹ã€‚
æ ¹æ®ARCHITECTURE.mdçš„è§„åˆ’ï¼Œä¸‹ä¸€æ­¥æ˜¯å®ç°æ¨¡å—åŒ–çš„æ¨ç†ç³»ç»Ÿ:

**ä¼˜å…ˆçº§:**
1. `src/utils/memory.py` - å†…å­˜ä¼°ç®—å…¬å¼
2. `src/inference/tiling.py` - åˆ†å—å’Œæ‹¼æ¥
3. `src/inference/preprocessor.py` - é¢„å¤„ç†
4. `src/inference/postprocessor.py` - åå¤„ç†
5. `src/inference/model_registry.py` - æ¨¡å‹ç®¡ç†
6. `src/inference/pipeline.py` - æµæ°´çº¿ç¼–æ’
7. `src/inference/analyzer.py` - è‡ªåŠ¨åˆ†æ

**åŒæ¨¡å‹ç­–ç•¥:**
- è®­ç»ƒcoarse_p4_r4æ¨¡å‹ (4å±‚é‡‘å­—å¡”)
- è®­ç»ƒfine_p2_r4æ¨¡å‹ (2å±‚é‡‘å­—å¡”ï¼Œå‚è€ƒRAFT-DIC)
- æ¨ç†æ—¶å…ˆcoarseå†fineï¼Œå®ç°å¤§ä½ç§»+é«˜ç²¾åº¦

è¯¦è§: [ARCHITECTURE.md](ARCHITECTURE.md)

---

## é™„å½•: å‚æ•°é‡ä¼°ç®—

```python
# BasicEncoder
conv1: 1Ã—32Ã—7Â³ = 10,976
layer1-3: ~500K (bottleneck blocks)
conv2: 96Ã—128Ã—1 = 12,288
æ€»è®¡: ~513K

# ContextEncoder
å…±äº«BasicEncoder: ~513K

# CorrBlock
æ— å¯å­¦ä¹ å‚æ•° (åªæ˜¯indexing)

# MotionEncoder
convc1: 2916Ã—96Ã—1 = 280K
convf1,2: ~18K
conv: ~82K
æ€»è®¡: ~380K

# ConvGRU3D
convz,r,q: 3 Ã— (96+195)Ã—96Ã—27 = 2.3M

# FlowHead
conv1,2: ~160K

# å…¨æ¨¡å‹æ€»å‚æ•°é‡
~3.8M (è¾ƒå°ï¼Œé€‚åˆåœ¨æœ‰é™æ•°æ®ä¸Šè®­ç»ƒ)
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-02
**ä½œè€…**: Claude (based on codebase analysis)
